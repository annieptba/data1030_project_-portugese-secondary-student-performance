{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## REGRESSION WITH MIDTERM SCORES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn as sns \n",
    "from matplotlib import pylab as plt\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis,KNeighborsClassifier)\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    "from  sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate path and load data\n",
    "path_to_data = \"/Users/anniephan/Desktop/Data_Science_Master/DATA_1030/data1030_project_-portugese-secondary-student-performance/data/student\"\n",
    "mat = pd.read_csv(path_to_data+'/student-mat.csv', sep=\";\")\n",
    "por = pd.read_csv(path_to_data+'/student-por.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets\n",
    "df = pd.concat([mat,por])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['school', 'sex', 'age', 'address', 'family_size', 'parents_status',\n",
      "       'mother_education', 'father_education', 'mother_job', 'father_job',\n",
      "       'reason', 'guardian', 'commute_time', 'study_time', 'failures',\n",
      "       'school_support', 'family_support', 'paid_classes', 'activities',\n",
      "       'nursery', 'desire_higher_edu', 'internet', 'romantic',\n",
      "       'family_quality', 'free_time', 'go_out', 'weekday_alcohol_usage',\n",
      "       'weekend_alcohol_usage', 'health', 'absences', 'period1_score',\n",
      "       'period2_score', 'final_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# rename column labels\n",
    "df.columns = ['school','sex','age','address','family_size','parents_status','mother_education','father_education',\n",
    "           'mother_job','father_job','reason','guardian','commute_time','study_time','failures','school_support',\n",
    "          'family_support','paid_classes','activities','nursery','desire_higher_edu','internet','romantic','family_quality',\n",
    "          'free_time','go_out','weekday_alcohol_usage','weekend_alcohol_usage','health','absences','period1_score','period2_score','final_score']\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>family_size</th>\n",
       "      <th>parents_status</th>\n",
       "      <th>mother_education</th>\n",
       "      <th>father_education</th>\n",
       "      <th>mother_job</th>\n",
       "      <th>father_job</th>\n",
       "      <th>...</th>\n",
       "      <th>free_time</th>\n",
       "      <th>go_out</th>\n",
       "      <th>weekday_alcohol_usage</th>\n",
       "      <th>weekend_alcohol_usage</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>period1_score</th>\n",
       "      <th>period2_score</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address family_size parents_status  mother_education  \\\n",
       "0     GP   F   18       U         GT3              A                 4   \n",
       "1     GP   F   17       U         GT3              T                 1   \n",
       "2     GP   F   15       U         LE3              T                 1   \n",
       "3     GP   F   15       U         GT3              T                 4   \n",
       "4     GP   F   16       U         GT3              T                 3   \n",
       "\n",
       "   father_education mother_job father_job  ... free_time go_out  \\\n",
       "0                 4    at_home    teacher  ...         3      4   \n",
       "1                 1    at_home      other  ...         3      3   \n",
       "2                 1    at_home      other  ...         3      2   \n",
       "3                 2     health   services  ...         2      2   \n",
       "4                 3      other      other  ...         3      2   \n",
       "\n",
       "   weekday_alcohol_usage  weekend_alcohol_usage  health absences  \\\n",
       "0                      1                      1       3        6   \n",
       "1                      1                      1       3        4   \n",
       "2                      2                      3       3       10   \n",
       "3                      1                      1       5        2   \n",
       "4                      1                      2       5        4   \n",
       "\n",
       "  period1_score period2_score final_score final_grade  \n",
       "0             5             6           6        poor  \n",
       "1             5             5           6        poor  \n",
       "2             7             8          10        fair  \n",
       "3            15            14          15        good  \n",
       "4             6            10          10        fair  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert final_score to categorical variable # Good:15~20 Fair:10~14 Poor:0~9\n",
    "df['final_grade'] = 'na'\n",
    "df.loc[(df.final_score >= 15) & (df.final_score <= 20), 'final_grade'] = 'good' \n",
    "df.loc[(df.final_score >= 10) & (df.final_score <= 14), 'final_grade'] = 'fair' \n",
    "df.loc[(df.final_score >= 0) & (df.final_score <= 9), 'final_grade'] = 'poor' \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate feature matrix and target variable\n",
    "df_reg = df.drop(columns=[\"final_grade\"])\n",
    "y_reg = df_reg['final_score'] #predict final grades so make final grades the target variable\n",
    "X_reg = df_reg.loc[:, df_reg.columns != 'final_score'] \n",
    "#print(\"target variable:\",y_reg)\n",
    "#print(\"feature matrix:\", X_reg.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data using Basic Split\n",
    "random_state = 42\n",
    "\n",
    "# first split to separate out the training set\n",
    "X_reg_train, X_reg_other, y_reg_train, y_reg_other = train_test_split(X_reg,y_reg,train_size = 0.6,random_state=random_state)\n",
    "#print('training set:',X_reg_train.shape, X_reg_train.head(3), y_reg_train.shape, y_reg_train.head(3)) \n",
    "#print(X_reg_other.shape, y_reg_other.shape) \n",
    "\n",
    "# second split to separate out the validation and test sets\n",
    "X_reg_val, X_reg_test, y_reg_val, y_reg_test = train_test_split(X_reg_other,y_reg_other,train_size = 0.5,random_state=random_state)\n",
    "#print('validation set:',X_reg_val.shape, X_reg_val.head(3),y_reg_val.shape, y_reg_val.head(3)) \n",
    "#print('test set:', X_reg_test.shape, X_reg_test.head(3), y_reg_test.shape, y_reg_test.head(3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(626, 32)\n",
      "(626, 55)\n"
     ]
    }
   ],
   "source": [
    "# collect which encoder to use on each feature\n",
    "# needs to be done manually\n",
    "onehot_ftrs = ['school','sex','age','address','family_size','parents_status', \n",
    "               'mother_job','father_job','reason','guardian','school_support',\n",
    "               'family_support','paid_classes','activities','nursery','desire_higher_edu','internet','romantic']\n",
    "minmax_ftrs = ['age','absences']\n",
    "std_ftrs = ['period1_score','period2_score']\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)]) # for now we only preprocess \n",
    "                                                       # later on we will add other steps here\n",
    "\n",
    "X_reg_train_prep = clf.fit_transform(X_reg_train)\n",
    "X_reg_val_prep = clf.transform(X_reg_val)\n",
    "X_reg_test_prep = clf.transform(X_reg_test)\n",
    "\n",
    "print(X_reg_train.shape)\n",
    "print(X_reg_train_prep.shape)\n",
    "\n",
    "# the target variable still needs to be preprocessed separately\n",
    "#le = LabelEncoder()\n",
    "#y_train_prep = le.fit_transform(y_train)\n",
    "#y_val_prep = le.transform(y_val)\n",
    "#y_test_prep = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(\"https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt\", sep='\\t')\n",
    "#df.head()\n",
    "\n",
    "#y = df['Y']\n",
    "#X = df.loc[:, df.columns != 'Y']\n",
    "\n",
    "mean_test_scores = []\n",
    "std_test_scores = []\n",
    "def MLpipe_KFold_RMSE(X,y,preprocessor,ML_algo,param_grid):\n",
    "    '''\n",
    "    This function splits the data to other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    The RMSE is minimized in cross-validation.\n",
    "    '''\n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "    \n",
    "    \n",
    "    # loop through 10 random states (2 points)\n",
    "    for i in range(1,10):\n",
    "    \n",
    "        # split data to other/test 80/20, and the use KFold with 4 folds (2 points)\n",
    "       # first split to separate out the test set\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,random_state=42*i)\n",
    "        #print(X_other.shape,y_other.shape)\n",
    "        #print('test set:',X_test.shape,y_test.shape)\n",
    "\n",
    "        # do KFold split on other\n",
    "        kf = KFold(n_splits=4,shuffle=True,random_state=42*i)\n",
    "\n",
    "        # preprocess the data (1 point)\n",
    "        pipe = make_pipeline(preprocessor,ML_algo)\n",
    "        \n",
    "        # loop through the hyperparameter combinations or use GridSearchCV (2 points)\n",
    "        ##calculate RMSE evaluation metric\n",
    "        RMSE = make_scorer(mean_squared_error, squared=False, greater_is_better=False)\n",
    "        ##create grid search CV with the pipeline, parameter grid, and scoring metric\n",
    "        grid = GridSearchCV(pipe, param_grid=param_grid,scoring = RMSE,\n",
    "                        cv=kf, return_train_score = True, n_jobs = -1)\n",
    "        \n",
    "        \n",
    "        # for each combination, calculate the train and validation scores using the evaluation metric\n",
    "        grid.fit(X_other, y_other)\n",
    "        \n",
    "        #save results to a datafrmae\n",
    "        #results = pd.DataFrame(grid.cv_results_)\n",
    "        #print(results[['params', 'mean_test_score', 'mean_train_score']])\n",
    "\n",
    "        # find which hyperparameter combination gives the best validation score (1 point)\n",
    "        print(\"best model parameters:\", grid.best_params_)\n",
    "        print('validation score:',grid.best_score_)\n",
    "\n",
    "        # calculate the test score (1 point)\n",
    "        best_models.append(grid)\n",
    "        test_score = mean_squared_error(y_test,best_models[-1].predict(X_test), squared=False)\n",
    "        print('test score:', test_score)\n",
    "\n",
    "        # append the test score and the best model to the lists (1 point)\n",
    "        test_scores.append(test_score)\n",
    "        \n",
    "    return best_models, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply on models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'lasso__alpha': 0.01}\n",
      "validation score: -3.6657068477726606\n",
      "test score: 3.695069214127115\n",
      "best model parameters: {'lasso__alpha': 0.01}\n",
      "validation score: -3.5994948742273327\n",
      "test score: 4.026263354038885\n",
      "best model parameters: {'lasso__alpha': 0.001}\n",
      "validation score: -3.4743607906502536\n",
      "test score: 4.33080062551237\n",
      "best model parameters: {'lasso__alpha': 0.01}\n",
      "validation score: -3.7215419497793443\n",
      "test score: 3.464389169250805\n",
      "best model parameters: {'lasso__alpha': 0.01}\n",
      "validation score: -3.718136068487915\n",
      "test score: 3.520099975313247\n",
      "best model parameters: {'lasso__alpha': 0.01}\n",
      "validation score: -3.6565427156512817\n",
      "test score: 3.8286814567352567\n",
      "best model parameters: {'lasso__alpha': 0.01}\n",
      "validation score: -3.7322090443402844\n",
      "test score: 3.541432734951768\n",
      "best model parameters: {'lasso__alpha': 0.01}\n",
      "validation score: -3.593049286848858\n",
      "test score: 4.102910760748988\n",
      "best model parameters: {'lasso__alpha': 0.01}\n",
      "validation score: -3.7647471381354367\n",
      "test score: 3.3982358668793418\n",
      "[3.695069214127115, 4.026263354038885, 4.33080062551237, 3.464389169250805, 3.520099975313247, 3.8286814567352567, 3.541432734951768, 4.102910760748988, 3.3982358668793418]\n",
      "mean test score: [3.7675425730619754]\n",
      "standard deviation test score: [0.30664876322172613]\n"
     ]
    }
   ],
   "source": [
    "#1. lasso\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs)])\n",
    "    \n",
    "ML_algo = Lasso()\n",
    "param_grid = {'lasso__alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2]}\n",
    "\n",
    "models, scores = MLpipe_KFold_RMSE(X_reg,y_reg,preprocessor,ML_algo,param_grid)\n",
    "print(scores)\n",
    "\n",
    "#calculate mean and standard deviation of test scores\n",
    "mean_test_score = np.mean(scores)\n",
    "std_test_score = np.std(scores)\n",
    "\n",
    "#append to the list\n",
    "mean_test_scores.append(mean_test_score)\n",
    "std_test_scores.append(std_test_score)\n",
    "\n",
    "print(\"mean test score:\", mean_test_scores)\n",
    "print(\"standard deviation test score:\", std_test_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'ridge__alpha': 10.0}\n",
      "validation score: -3.669721481299898\n",
      "test score: 3.7003999188900387\n",
      "best model parameters: {'ridge__alpha': 10.0}\n",
      "validation score: -3.592041948747581\n",
      "test score: 4.034897807355533\n",
      "best model parameters: {'ridge__alpha': 1.0}\n",
      "validation score: -3.4745917759114944\n",
      "test score: 4.329638753634537\n",
      "best model parameters: {'ridge__alpha': 10.0}\n",
      "validation score: -3.724974526524874\n",
      "test score: 3.453163346748056\n",
      "best model parameters: {'ridge__alpha': 10.0}\n",
      "validation score: -3.719696753897033\n",
      "test score: 3.538147543745812\n",
      "best model parameters: {'ridge__alpha': 100.0}\n",
      "validation score: -3.655874319274848\n",
      "test score: 3.82075744077414\n",
      "best model parameters: {'ridge__alpha': 10.0}\n",
      "validation score: -3.7351252879772523\n",
      "test score: 3.5570793025155476\n",
      "best model parameters: {'ridge__alpha': 100.0}\n",
      "validation score: -3.596632373238987\n",
      "test score: 4.096496869243828\n",
      "best model parameters: {'ridge__alpha': 10.0}\n",
      "validation score: -3.7627715077336594\n",
      "test score: 3.3993195901062414\n",
      "[3.7003999188900387, 4.034897807355533, 4.329638753634537, 3.453163346748056, 3.538147543745812, 3.82075744077414, 3.5570793025155476, 4.096496869243828, 3.3993195901062414]\n",
      "mean test score: [3.7675425730619754, 3.769988952557082]\n",
      "standard deviation test score: [0.30664876322172613, 0.3044607788159095]\n"
     ]
    }
   ],
   "source": [
    "#2. linear regression with l2 regularization\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs)]) \n",
    "\n",
    "ML_algo = Ridge()\n",
    "param_grid = {'ridge__alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2]}\n",
    "\n",
    "models, scores = MLpipe_KFold_RMSE(X_reg,y_reg,preprocessor,ML_algo,param_grid)\n",
    "print(scores)\n",
    "\n",
    "#calculate mean and standard deviation of test scores\n",
    "mean_test_score = np.mean(scores)\n",
    "std_test_score = np.std(scores)\n",
    "\n",
    "#append to the list\n",
    "mean_test_scores.append(mean_test_score)\n",
    "std_test_scores.append(std_test_score)\n",
    "\n",
    "print(\"mean test score:\", mean_test_scores)\n",
    "print(\"standard deviation test score:\", std_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "Best model is ridge alpha = 1, test score = 52.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'elasticnet__alpha': 0.01, 'elasticnet__l1_ratio': 0.9}\n",
      "validation score: -3.6659179791602696\n",
      "test score: 3.694792630955127\n",
      "best model parameters: {'elasticnet__alpha': 0.1, 'elasticnet__l1_ratio': 0.1}\n",
      "validation score: -3.5927259849628284\n",
      "test score: 4.008355814444964\n",
      "best model parameters: {'elasticnet__alpha': 0.01, 'elasticnet__l1_ratio': 0.30000000000000004}\n",
      "validation score: -3.4743718838233186\n",
      "test score: 4.317836177159574\n",
      "best model parameters: {'elasticnet__alpha': 0.01, 'elasticnet__l1_ratio': 0.9}\n",
      "validation score: -3.7221472607693027\n",
      "test score: 3.463201936408109\n",
      "best model parameters: {'elasticnet__alpha': 0.01, 'elasticnet__l1_ratio': 0.9}\n",
      "validation score: -3.718638901865286\n",
      "test score: 3.5216968982425088\n",
      "best model parameters: {'elasticnet__alpha': 0.1, 'elasticnet__l1_ratio': 0.1}\n",
      "validation score: -3.651496284112\n",
      "test score: 3.8232963562622873\n",
      "best model parameters: {'elasticnet__alpha': 0.1, 'elasticnet__l1_ratio': 0.1}\n",
      "validation score: -3.731721303941994\n",
      "test score: 3.5395353915701833\n",
      "best model parameters: {'elasticnet__alpha': 0.1, 'elasticnet__l1_ratio': 0.1}\n",
      "validation score: -3.5895018371351304\n",
      "test score: 4.0962182264880544\n",
      "best model parameters: {'elasticnet__alpha': 0.1, 'elasticnet__l1_ratio': 0.1}\n",
      "validation score: -3.7584023223699776\n",
      "test score: 3.3689821646509426\n",
      "[3.694792630955127, 4.008355814444964, 4.317836177159574, 3.463201936408109, 3.5216968982425088, 3.8232963562622873, 3.5395353915701833, 4.0962182264880544, 3.3689821646509426]\n",
      "mean test score: [3.7675425730619754, 3.769988952557082, 3.759323955131306]\n",
      "standard deviation test score: [0.30664876322172613, 0.3044607788159095, 0.3056024784101017]\n"
     ]
    }
   ],
   "source": [
    "#3. linear regression with an elastic net\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs)])\n",
    "ML_algo = ElasticNet()\n",
    "param_grid = {\"elasticnet__alpha\": [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "              \"elasticnet__l1_ratio\": np.linspace(0.1,0.9,5)}\n",
    "\n",
    "models, scores = MLpipe_KFold_RMSE(X_reg,y_reg,preprocessor,ML_algo,param_grid)\n",
    "print(scores)\n",
    "\n",
    "#calculate mean and standard deviation of test scores\n",
    "mean_test_score = np.mean(scores)\n",
    "std_test_score = np.std(scores)\n",
    "\n",
    "#append to the list\n",
    "mean_test_scores.append(mean_test_score)\n",
    "std_test_scores.append(std_test_score)\n",
    "\n",
    "print(\"mean test score:\", mean_test_scores)\n",
    "print(\"standard deviation test score:\", std_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "Best model is elastic net alpha = 0.1 and l1_ratio = 0.1, test score = 51.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 0.5}\n",
      "validation score: -3.598690384274318\n",
      "test score: 3.6820390046704947\n",
      "best model parameters: {'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 0.1}\n",
      "validation score: -3.5812647447860884\n",
      "test score: 3.971971713360318\n",
      "best model parameters: {'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 0.5}\n",
      "validation score: -3.432861029284001\n",
      "test score: 4.212718470464008\n",
      "best model parameters: {'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 0.5}\n",
      "validation score: -3.6739116233506137\n",
      "test score: 3.477425173936794\n",
      "best model parameters: {'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 0.5}\n",
      "validation score: -3.6150901801935893\n",
      "test score: 3.4433784588296934\n",
      "best model parameters: {'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 0.5}\n",
      "validation score: -3.5667713692763594\n",
      "test score: 3.8933182488576934\n",
      "best model parameters: {'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 0.5}\n",
      "validation score: -3.684113923994224\n",
      "test score: 3.3269318960978085\n",
      "best model parameters: {'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 0.5}\n",
      "validation score: -3.517989936241716\n",
      "test score: 4.058678422781877\n",
      "best model parameters: {'randomforestregressor__max_depth': 5, 'randomforestregressor__max_features': 0.5}\n",
      "validation score: -3.6726210421034073\n",
      "test score: 3.4213816668907104\n",
      "[3.6820390046704947, 3.971971713360318, 4.212718470464008, 3.477425173936794, 3.4433784588296934, 3.8933182488576934, 3.3269318960978085, 4.058678422781877, 3.4213816668907104]\n",
      "mean test score: [3.7675425730619754, 3.769988952557082, 3.759323955131306, 3.7208714506543776]\n",
      "standard deviation test score: [0.30664876322172613, 0.3044607788159095, 0.3056024784101017, 0.30395087207177396]\n"
     ]
    }
   ],
   "source": [
    "#4. RF\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs)])\n",
    "ML_algo = RandomForestRegressor()\n",
    "param_grid = {\n",
    "              'randomforestregressor__max_depth': [1,3,5], #we have 10 X features\n",
    "                'randomforestregressor__max_features': [0.5,1, 0.1]\n",
    "              } \n",
    "    \n",
    "models, scores = MLpipe_KFold_RMSE(X_reg,y_reg,preprocessor,ML_algo,param_grid)\n",
    "print(scores)\n",
    "\n",
    "\n",
    "#calculate mean and standard deviation of test scores\n",
    "mean_test_score = np.mean(scores)\n",
    "std_test_score = np.std(scores)\n",
    "\n",
    "#append to the list\n",
    "mean_test_scores.append(mean_test_score)\n",
    "std_test_scores.append(std_test_score)\n",
    "\n",
    "print(\"mean test score:\", mean_test_scores)\n",
    "print(\"standard deviation test score:\", std_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "Best model is random forest regressor max_dept = 5 and max_features = -.5, test score = 50.45"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'svr__C': 10.0, 'svr__epsilon': 1}\n",
      "validation score: -3.631480093299362\n",
      "test score: 3.621609928707777\n",
      "best model parameters: {'svr__C': 10.0, 'svr__epsilon': 1}\n",
      "validation score: -3.543267062422064\n",
      "test score: 4.023277322706731\n",
      "best model parameters: {'svr__C': 10.0, 'svr__epsilon': 1}\n",
      "validation score: -3.3942014933393128\n",
      "test score: 4.26533537873122\n",
      "best model parameters: {'svr__C': 10.0, 'svr__epsilon': 1}\n",
      "validation score: -3.6982946337576776\n",
      "test score: 3.38126981786577\n",
      "best model parameters: {'svr__C': 10.0, 'svr__epsilon': 1}\n",
      "validation score: -3.618817258284515\n",
      "test score: 3.4312042423289886\n",
      "best model parameters: {'svr__C': 1.0, 'svr__epsilon': 1}\n",
      "validation score: -3.6194471524575693\n",
      "test score: 3.793747349301585\n",
      "best model parameters: {'svr__C': 1.0, 'svr__epsilon': 1}\n",
      "validation score: -3.702034229659945\n",
      "test score: 3.404689183487551\n",
      "best model parameters: {'svr__C': 10.0, 'svr__epsilon': 1}\n",
      "validation score: -3.5254196114208365\n",
      "test score: 4.092280160559035\n",
      "best model parameters: {'svr__C': 10.0, 'svr__epsilon': 1}\n",
      "validation score: -3.6459877483479604\n",
      "test score: 3.4632899626665026\n",
      "[3.621609928707777, 4.023277322706731, 4.26533537873122, 3.38126981786577, 3.4312042423289886, 3.793747349301585, 3.404689183487551, 4.092280160559035, 3.4632899626665026]\n",
      "mean test score: [3.7675425730619754, 3.769988952557082, 3.759323955131306, 3.7208714506543776, 3.719633705150573]\n",
      "standard deviation test score: [0.30664876322172613, 0.3044607788159095, 0.3056024784101017, 0.30395087207177396, 0.3173747308494015]\n"
     ]
    }
   ],
   "source": [
    "#5. SVR\n",
    "from sklearn.svm import SVR\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs)])\n",
    "ML_algo = SVR()\n",
    "param_grid = {'svr__C': np.logspace(-3,4,num=8),'svr__epsilon': [0,1,0.1]}\n",
    "    \n",
    "models, scores = MLpipe_KFold_RMSE(X_reg,y_reg,preprocessor,ML_algo,param_grid)\n",
    "print(scores)\n",
    "\n",
    "\n",
    "#calculate mean and standard deviation of test scores\n",
    "mean_test_score = np.mean(scores)\n",
    "std_test_score = np.std(scores)\n",
    "\n",
    "#append to the list\n",
    "mean_test_scores.append(mean_test_score)\n",
    "std_test_scores.append(std_test_score)\n",
    "\n",
    "print(\"mean test score:\", mean_test_scores)\n",
    "print(\"standard deviation test score:\", std_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "Best model is SVR C = 10 and epsilon = 1, test score = 51.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'kneighborsregressor__n_neighbors': 17, 'kneighborsregressor__weights': 'uniform'}\n",
      "validation score: -3.698104808582039\n",
      "test score: 3.826262851982344\n",
      "best model parameters: {'kneighborsregressor__n_neighbors': 49, 'kneighborsregressor__weights': 'distance'}\n",
      "validation score: -3.6214185344168626\n",
      "test score: 4.28910196397092\n",
      "best model parameters: {'kneighborsregressor__n_neighbors': 37, 'kneighborsregressor__weights': 'distance'}\n",
      "validation score: -3.516413332206306\n",
      "test score: 4.301963368773572\n",
      "best model parameters: {'kneighborsregressor__n_neighbors': 41, 'kneighborsregressor__weights': 'distance'}\n",
      "validation score: -3.75532988683083\n",
      "test score: 3.531512512102614\n",
      "best model parameters: {'kneighborsregressor__n_neighbors': 45, 'kneighborsregressor__weights': 'distance'}\n",
      "validation score: -3.753174081248021\n",
      "test score: 3.414205687076857\n",
      "best model parameters: {'kneighborsregressor__n_neighbors': 33, 'kneighborsregressor__weights': 'uniform'}\n",
      "validation score: -3.7137641263312897\n",
      "test score: 3.847945377233201\n",
      "best model parameters: {'kneighborsregressor__n_neighbors': 49, 'kneighborsregressor__weights': 'distance'}\n",
      "validation score: -3.8111787382558466\n",
      "test score: 3.491293375321542\n",
      "best model parameters: {'kneighborsregressor__n_neighbors': 13, 'kneighborsregressor__weights': 'uniform'}\n",
      "validation score: -3.619269970779717\n",
      "test score: 4.247342650949587\n",
      "best model parameters: {'kneighborsregressor__n_neighbors': 49, 'kneighborsregressor__weights': 'distance'}\n",
      "validation score: -3.7207673221533692\n",
      "test score: 3.4902138174513033\n",
      "[3.826262851982344, 4.28910196397092, 4.301963368773572, 3.531512512102614, 3.414205687076857, 3.847945377233201, 3.491293375321542, 4.247342650949587, 3.4902138174513033]\n",
      "mean test score: [3.7675425730619754, 3.769988952557082, 3.759323955131306, 3.7208714506543776, 3.719633705150573, 3.826649067206882]\n",
      "standard deviation test score: [0.30664876322172613, 0.3044607788159095, 0.3056024784101017, 0.30395087207177396, 0.3173747308494015, 0.3496173123278884]\n"
     ]
    }
   ],
   "source": [
    "#6. KNN Regressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "ML_algo = KNeighborsRegressor()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs)])\n",
    "param_grid = {'kneighborsregressor__n_neighbors': np.arange(1,50,4), 'kneighborsregressor__weights': ['uniform', 'distance']}\n",
    "\n",
    "models, scores = MLpipe_KFold_RMSE(X_reg,y_reg,preprocessor,ML_algo,param_grid)\n",
    "print(scores)\n",
    "\n",
    "\n",
    "#calculate mean and standard deviation of test scores\n",
    "mean_test_score = np.mean(scores)\n",
    "std_test_score = np.std(scores)\n",
    "\n",
    "#append to the list\n",
    "mean_test_scores.append(mean_test_score)\n",
    "std_test_scores.append(std_test_score)\n",
    "\n",
    "print(\"mean test score:\", mean_test_scores)\n",
    "print(\"standard deviation test score:\", std_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best model for KNN: \n",
    "- best model parameters: {'kneighborsregressor__n_neighbors': 13, 'kneighborsregressor__weights': 'distance'}\n",
    "- validation score: -58.215665294941545\n",
    "- test score: 50.46210682730428"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_models = ['lasso regression', 'ride regression', 'elastic net', 'random forest', 'SVR', 'KNN-Regression']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, \" mean and standard deviation of each algo's best models\")"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.errorbar(ML_models ,mean_test_scores, yerr = std_test_scores, fmt=\"o\")\n",
    "plt.xlabel(\"ML Models\")\n",
    "plt.ylabel(\" mean and standard deviation of each algo's best models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "Random forest have least mean and standard deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
