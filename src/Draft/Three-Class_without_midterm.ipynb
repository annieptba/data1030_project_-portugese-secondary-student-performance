{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFICATION WITHOUT MIDTERM SCORES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading and set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import seaborn as sns \n",
    "from matplotlib import pylab as plt\n",
    "from sklearn.model_selection import train_test_split,KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Lasso\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "from sklearn.datasets import make_regression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import (NeighborhoodComponentsAnalysis,KNeighborsClassifier)\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import make_moons\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    "from  sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initiate path and load data\n",
    "path_to_data = \"/Users/anniephan/Desktop/Data_Science_Master/DATA_1030/data1030_project_-portugese-secondary-student-performance/data/student\"\n",
    "mat = pd.read_csv(path_to_data+'/student-mat.csv', sep=\";\")\n",
    "por = pd.read_csv(path_to_data+'/student-por.csv', sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge datasets\n",
    "df = pd.concat([mat,por])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['school', 'sex', 'age', 'address', 'family_size', 'parents_status',\n",
      "       'mother_education', 'father_education', 'mother_job', 'father_job',\n",
      "       'reason', 'guardian', 'commute_time', 'study_time', 'failures',\n",
      "       'school_support', 'family_support', 'paid_classes', 'activities',\n",
      "       'nursery', 'desire_higher_edu', 'internet', 'romantic',\n",
      "       'family_quality', 'free_time', 'go_out', 'weekday_alcohol_usage',\n",
      "       'weekend_alcohol_usage', 'health', 'absences', 'period1_score',\n",
      "       'period2_score', 'final_score'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# rename column labels\n",
    "df.columns = ['school','sex','age','address','family_size','parents_status','mother_education','father_education',\n",
    "           'mother_job','father_job','reason','guardian','commute_time','study_time','failures','school_support',\n",
    "          'family_support','paid_classes','activities','nursery','desire_higher_edu','internet','romantic','family_quality',\n",
    "          'free_time','go_out','weekday_alcohol_usage','weekend_alcohol_usage','health','absences','period1_score','period2_score','final_score']\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>family_size</th>\n",
       "      <th>parents_status</th>\n",
       "      <th>mother_education</th>\n",
       "      <th>father_education</th>\n",
       "      <th>mother_job</th>\n",
       "      <th>father_job</th>\n",
       "      <th>...</th>\n",
       "      <th>free_time</th>\n",
       "      <th>go_out</th>\n",
       "      <th>weekday_alcohol_usage</th>\n",
       "      <th>weekend_alcohol_usage</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>period1_score</th>\n",
       "      <th>period2_score</th>\n",
       "      <th>final_score</th>\n",
       "      <th>final_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address family_size parents_status  mother_education  \\\n",
       "0     GP   F   18       U         GT3              A                 4   \n",
       "1     GP   F   17       U         GT3              T                 1   \n",
       "2     GP   F   15       U         LE3              T                 1   \n",
       "3     GP   F   15       U         GT3              T                 4   \n",
       "4     GP   F   16       U         GT3              T                 3   \n",
       "\n",
       "   father_education mother_job father_job  ... free_time go_out  \\\n",
       "0                 4    at_home    teacher  ...         3      4   \n",
       "1                 1    at_home      other  ...         3      3   \n",
       "2                 1    at_home      other  ...         3      2   \n",
       "3                 2     health   services  ...         2      2   \n",
       "4                 3      other      other  ...         3      2   \n",
       "\n",
       "   weekday_alcohol_usage  weekend_alcohol_usage  health absences  \\\n",
       "0                      1                      1       3        6   \n",
       "1                      1                      1       3        4   \n",
       "2                      2                      3       3       10   \n",
       "3                      1                      1       5        2   \n",
       "4                      1                      2       5        4   \n",
       "\n",
       "  period1_score period2_score final_score final_grade  \n",
       "0             5             6           6        poor  \n",
       "1             5             5           6        poor  \n",
       "2             7             8          10        fair  \n",
       "3            15            14          15        good  \n",
       "4             6            10          10        fair  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert final_score to categorical variable # Good:15~20 Fair:10~14 Poor:0~9\n",
    "df['final_grade'] = 'na'\n",
    "df.loc[(df.final_score >= 15) & (df.final_score <= 20), 'final_grade'] = 'good' \n",
    "df.loc[(df.final_score >= 10) & (df.final_score <= 14), 'final_grade'] = 'fair' \n",
    "df.loc[(df.final_score >= 0) & (df.final_score <= 9), 'final_grade'] = 'poor' \n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>family_size</th>\n",
       "      <th>parents_status</th>\n",
       "      <th>mother_education</th>\n",
       "      <th>father_education</th>\n",
       "      <th>mother_job</th>\n",
       "      <th>father_job</th>\n",
       "      <th>...</th>\n",
       "      <th>internet</th>\n",
       "      <th>romantic</th>\n",
       "      <th>family_quality</th>\n",
       "      <th>free_time</th>\n",
       "      <th>go_out</th>\n",
       "      <th>weekday_alcohol_usage</th>\n",
       "      <th>weekend_alcohol_usage</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>final_grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>poor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>fair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address family_size parents_status  mother_education  \\\n",
       "0     GP   F   18       U         GT3              A                 4   \n",
       "1     GP   F   17       U         GT3              T                 1   \n",
       "2     GP   F   15       U         LE3              T                 1   \n",
       "3     GP   F   15       U         GT3              T                 4   \n",
       "4     GP   F   16       U         GT3              T                 3   \n",
       "\n",
       "   father_education mother_job father_job  ... internet romantic  \\\n",
       "0                 4    at_home    teacher  ...       no       no   \n",
       "1                 1    at_home      other  ...      yes       no   \n",
       "2                 1    at_home      other  ...      yes       no   \n",
       "3                 2     health   services  ...      yes      yes   \n",
       "4                 3      other      other  ...       no       no   \n",
       "\n",
       "   family_quality  free_time  go_out weekday_alcohol_usage  \\\n",
       "0               4          3       4                     1   \n",
       "1               5          3       3                     1   \n",
       "2               4          3       2                     2   \n",
       "3               3          2       2                     1   \n",
       "4               4          3       2                     1   \n",
       "\n",
       "  weekend_alcohol_usage health absences final_grade  \n",
       "0                     1      3        6        poor  \n",
       "1                     1      3        4        poor  \n",
       "2                     3      3       10        fair  \n",
       "3                     1      5        2        good  \n",
       "4                     2      5        4        fair  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class = df.drop(['final_score'], axis = 1)\n",
    "df_class_no = df_class.drop(columns=['period1_score', 'period2_score'])\n",
    "df_class_no.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate feature matrix and target variable\n",
    "y_class_no = df_class_no['final_grade'] #predict final grades so make final grades the target variable\n",
    "X_class_no = df_class_no.loc[:, df_class_no.columns != 'final_grade'] \n",
    "#print(\"target variable:\",y_reg_no)\n",
    "#print(\"feature matrix:\", X_reg_no.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data using Basic Split\n",
    "random_state = 42\n",
    "\n",
    "# first split to separate out the training set\n",
    "X_class_no_train, X_class_no_other, y_class_no_train, y_class_no_other = train_test_split(X_class_no,y_class_no,train_size = 0.6,random_state=random_state)\n",
    "#print('training set:',X_class_no_train.shape, X_class_no_train.head(3), y_class_no_train.shape, y_class_no_train.head(3)) \n",
    "#print(X_class_no_other.shape, y_class_no_other.shape) \n",
    "\n",
    "# second split to separate out the validation and test sets\n",
    "X_class_no_val, X_class_no_test, y_class_no_val, y_class_no_test = train_test_split(X_class_no_other,y_class_no_other,train_size = 0.5,random_state=random_state)\n",
    "#print('validation set:',X_class_no_val.shape, X_class_no_val.head(3),y_class_no_val.shape, y_class_no_val.head(3)) \n",
    "#print('test set:', X_class_no_test.shape, X_class_no_test.head(3), y_class_no_test.shape, y_class_no_test.head(3)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(626, 30)\n",
      "(626, 53)\n"
     ]
    }
   ],
   "source": [
    "# collect which encoder to use on each feature\n",
    "# needs to be done manually\n",
    "onehot_ftrs = ['school','sex','age','address','family_size','parents_status', \n",
    "               'mother_job','father_job','reason','guardian','school_support',\n",
    "               'family_support','paid_classes','activities','nursery','desire_higher_edu','internet','romantic']\n",
    "minmax_ftrs = ['age','absences']\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)]) # for now we only preprocess \n",
    "                                                       # later on we will add other steps here\n",
    "\n",
    "X_class_no_train_prep = clf.fit_transform(X_class_no_train)\n",
    "X_class_no_val_prep = clf.transform(X_class_no_val)\n",
    "X_class_no_test_prep = clf.transform(X_class_no_test)\n",
    "\n",
    "print(X_class_no_train.shape)\n",
    "print(X_class_no_train_prep.shape)\n",
    "\n",
    "#apply label encoder to target variable \n",
    "le = LabelEncoder()\n",
    "y_class_no_train_prep = le.fit_transform(y_class_no_train)\n",
    "#print('Target variable for classifcation training prep set:', y_class_no_train.shape, y_class_no_train.head(3)) \n",
    "y_class_no_val_prep = le.transform(y_class_no_val)\n",
    "#print('Target variable for classifcation validation prep set:', y_class_no_val.shape, y_class_no_val.head(3)) \n",
    "y_class_no_test_prep = le.transform(y_class_no_test)\n",
    "#print('Target variable for classifcation validation prep set:', y_class_no_test.shape, y_class_no_test.head(3)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     1044\n",
       "unique       3\n",
       "top       fair\n",
       "freq       610\n",
       "Name: final_grade, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_class['final_grade'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5842911877394636"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "610/len(df_class['final_grade'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_test_scores = []\n",
    "std_test_scores = []\n",
    "def MLpipe_KFold_Acc(X,y,preprocessor,ML_algo,param_grid):\n",
    "    '''\n",
    "    This function splits the data to other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    The RMSE is minimized in cross-validation.\n",
    "    '''\n",
    "    test_scores = np.zeros(10)\n",
    "    best_models = []\n",
    "    \n",
    "    \n",
    "    # loop through 10 random states (2 points)\n",
    "    for i in range(1,10):\n",
    "    \n",
    "        # split data to other/test 80/20, and the use KFold with 4 folds (2 points)\n",
    "        # first split to separate out the test set\n",
    "        X_other, X_test, y_other, y_test = train_test_split(X,y,test_size = 0.2,random_state=42*i)\n",
    "        #print(X_other.shape,y_other.shape)\n",
    "        #print('test set:',X_test.shape,y_test.shape)\n",
    "        \n",
    "        #label encoder\n",
    "        le = LabelEncoder()\n",
    "        y_other_prep = le.fit_transform(y_other)\n",
    "        y_test_prep = le.transform(y_test)\n",
    "\n",
    "        # do KFold split on other\n",
    "        kf = KFold(n_splits=4,shuffle=True,random_state=42*i)\n",
    "\n",
    "        # preprocess the data (1 point)\n",
    "        pipe = make_pipeline(preprocessor,ML_algo)\n",
    "        \n",
    "        # loop through the hyperparameter combinations or use GridSearchCV (2 points)\n",
    "        ##create grid search CV with the pipeline, parameter grid, and scoring metric\n",
    "        grid = GridSearchCV(pipe, param_grid=param_grid,scoring = make_scorer(accuracy_score, greater_is_better=True),\n",
    "                        cv=kf, return_train_score = True, n_jobs = -1)\n",
    "\n",
    "        # for each combination, calculate the train and validation scores using the evaluation metric\n",
    "        grid.fit(X_other, y_other_prep)\n",
    "        \n",
    "        #save results to a datafrmae\n",
    "        #results = pd.DataFrame(grid.cv_results_)\n",
    "        #print(results[['params', 'mean_test_score', 'mean_train_score']])\n",
    "\n",
    "        # find which hyperparameter combination gives the best validation score (1 point)\n",
    "        print(\"best model parameters:\", grid.best_params_)\n",
    "        print('validation score:',grid.best_score_)\n",
    "\n",
    "        # calculate the best model\n",
    "        best_models.append(grid)\n",
    "        \n",
    "        # calculate and save the test score\n",
    "        y_test_pred = best_models[-1].predict(X_test)\n",
    "        test_scores[i] = accuracy_score(y_test_prep,y_test_pred)\n",
    "        print('test score:', test_scores[i])\n",
    "        \n",
    "    return best_models, test_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply on models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the baseline, maximum, the proportion of the most popular class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "Best model is elastic net alpha = 0.1 and l1_ratio = 0.1, test score = 51.44"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.6036299227088701\n",
      "test score: 0.507177033492823\n",
      "best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.5904720279720279\n",
      "test score: 0.569377990430622\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.5939685314685315\n",
      "test score: 0.5454545454545454\n",
      "best model parameters: {'randomforestclassifier__max_depth': 30, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.5856413323518587\n",
      "test score: 0.5598086124401914\n",
      "best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.5903570114096429\n",
      "test score: 0.5598086124401914\n",
      "best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.5940605447184395\n",
      "test score: 0.5550239234449761\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75}\n",
      "validation score: 0.5688546650717703\n",
      "test score: 0.6172248803827751\n",
      "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5}\n",
      "validation score: 0.5952107103422893\n",
      "test score: 0.5406698564593302\n",
      "best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 1.0}\n",
      "validation score: 0.5724374309900626\n",
      "test score: 0.5406698564593302\n",
      "[0.         0.50717703 0.56937799 0.54545455 0.55980861 0.55980861\n",
      " 0.55502392 0.61722488 0.54066986 0.54066986]\n",
      "mean test score: [0.49952153110047853]\n",
      "standard deviation test score: [0.16857050785011932]\n"
     ]
    }
   ],
   "source": [
    "#1. RF Classifier\n",
    "#ML ago\n",
    "ML_algo = RandomForestClassifier()\n",
    "#encoders and preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs)])\n",
    "#parameters\n",
    "param_grid = {\n",
    "              'randomforestclassifier__max_depth': [1, 3, 10, 30], # the max_depth should be smaller or equal than the number of features roughly\n",
    "              'randomforestclassifier__max_features': [0.5,0.75,1.0]# linearly spaced between 0.5 and 1\n",
    "              }\n",
    "#calculation\n",
    "models, scores = MLpipe_KFold_Acc(X_class_no,y_class_no,preprocessor,ML_algo,param_grid)\n",
    "print(scores)\n",
    "\n",
    "\n",
    "#calculate mean and standard deviation of test scores\n",
    "mean_test_score = np.mean(scores)\n",
    "std_test_score = np.std(scores)\n",
    "\n",
    "#append to the list\n",
    "mean_test_scores.append(mean_test_score)\n",
    "std_test_scores.append(std_test_score)\n",
    "\n",
    "print(\"mean test score:\", mean_test_scores)\n",
    "print(\"standard deviation test score:\", std_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "Best model is random forest regressor \n",
    "best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5}\n",
    "validation score: 0.5700278340080972\n",
    "test score: 0.6363636363636364"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#ML ago\n",
    "ML_algo = SVC()\n",
    "#encoders and preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs)])\n",
    "#parameters\n",
    "param_grid = {'svc__C': np.logspace(-2,4,num=10),'svc__gamma': np.logspace(-2,4,num=10)}\n",
    "#calculation\n",
    "models, scores = MLpipe_KFold_Acc(X_class_no,y_class_no,preprocessor,ML_algo,param_grid)\n",
    "print(scores)\n",
    "\n",
    "\n",
    "#calculate mean and standard deviation of test scores\n",
    "mean_test_score = np.mean(scores)\n",
    "std_test_score = np.std(scores)\n",
    "\n",
    "#append to the list\n",
    "mean_test_scores.append(mean_test_score)\n",
    "std_test_scores.append(std_test_score)\n",
    "\n",
    "print(\"mean test score:\", mean_test_scores)\n",
    "print(\"standard deviation test score:\", std_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "Best model is SVC\n",
    "test score: 0.5980861244019139\n",
    "best model parameters: {'svc__C': 4.6415888336127775, 'svc__gamma': 2154.4346900318824}\n",
    "validation score: 0.5880049227088702\n",
    "test score: 0.6411483253588517"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. KNN Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#ML ago\n",
    "ML_algo = KNeighborsClassifier()\n",
    "#encoders and preprocessors\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(sparse=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs)])\n",
    "#parameters\n",
    "param_grid = {'kneighborsclassifier__n_neighbors': np.arange(1,50,4), 'kneighborsclassifier__weights': ['uniform', 'distance']}\n",
    "#calculation\n",
    "models, scores = MLpipe_KFold_Acc(X_class_no,y_class_no,preprocessor,ML_algo,param_grid)\n",
    "print(scores)\n",
    "\n",
    "#calculate mean and standard deviation of test scores\n",
    "mean_test_score = np.mean(scores)\n",
    "std_test_score = np.std(scores)\n",
    "\n",
    "#append to the list\n",
    "mean_test_scores.append(mean_test_score)\n",
    "std_test_scores.append(std_test_score)\n",
    "\n",
    "print(\"mean test score:\", mean_test_scores)\n",
    "print(\"standard deviation test score:\", std_test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "Best model is KNN:\n",
    "best model parameters: {'kneighborsclassifier__n_neighbors': 45, 'kneighborsclassifier__weights': 'uniform'}\n",
    "validation score: 0.5724546834744203\n",
    "test score: 0.6267942583732058"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_models = ['RF Classifier', 'SVC', 'KNN-Classification']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(ML_models ,mean_test_scores, yerr = std_test_scores, fmt=\"o\")\n",
    "plt.xlabel(\"ML Models\")\n",
    "plt.ylabel(\" mean and standard deviation of each algo's best models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "do analysis such as confusion matrix, feature importance is just a way to analyze model to see which features your model values the most, which contributes the mos tto prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[110,   2,  10],\n",
       "       [ 37,   3,   0],\n",
       "       [ 40,   0,   7]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = y_class_no_test_prep\n",
    "classifier = SVC(kernel='linear')\n",
    "classifier.fit(X_class_no_train_prep, y_class_no_train_prep)\n",
    "\n",
    "y_pred = classifier.predict(X_class_no_test_prep)\n",
    "\n",
    "classes=['class 0','class 1','class 2']\n",
    "\n",
    "confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVUAAAEGCAYAAADVFgZ3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xVdbnH8c93QFTkJiDIxRvE8QJeUkzRjnnLWyWKYpZ5Ka+djKxTanlSNC1TOxVmntBMsqOFiEet1BQtSwWVm9wyFBVB5CYCAgoz85w/1hodh2FmM7P27LWH75vXes1ea6/9W89evOaZ31q/y1JEYGZm2agodQBmZq2Jk6qZWYacVM3MMuSkamaWISdVM7MMtS11AKWkttuG2nUsdRi5td+eO5c6hNyrqnbvmYa8Mf913l6+TM0po02nXSIq1xW0b6xb+mhEHNec4zXXlp1U23Vk691PK3UYufXUM6NKHULurVxXWeoQcu2EI4Y0u4yoXFfw7+l7027p3uwDNtMWnVTNrBwIVD53Kp1UzSzfBFS0KXUUBXNSNbP8U7Nuy7YoJ1Uzyzlf/puZZcs1VTOzjAjXVM3MsiPXVM3MMuXWfzOzrLihyswsO8KX/2ZmmXJN1cwsK778NzPLjoA2bqgyM8uO76mamWWlvC7/yydSM9tySYUtjRajOyQtkTSz1raukh6TNDf9uX2t974r6WVJL0k6tpBQnVTNLP9UUdjSuDuBuk8GuByYEBEDgAnpOpL2Ak4HBqaf+aWkRm/uOqmaWb4VWkstoKYaEU8Bb9fZPBQYk74eA5xUa/vvI+L9iHgVeBn4RGPH8D1VM8u/woepdpf0Qq310RExupHP9IyIRQARsUhSj3R7H2Birf0WpNsa5KRqZjm3WQ1VyyJicHYH3kijT3r05b+Z5V9Gl/+bsFhSr+Qw6gUsSbcvAHaqtV9f4M3GCnNSNbN8q5lPNZuGqvo8CJydvj4beKDW9tMlbS1pN2AA8Fxjhfny38xyLrt+qpLuAQ4nufe6ALgKuB4YK+lcYD4wHCAiZkkaC8wGKoGvRURVY8dwUjWz/MtoPtWI+MIm3jpqE/tfB1y3OcdwUjWz/PMwVTOzjKi8hqk6qZpZ/rmmamaWHTmpmpllI3maipOqmVk2JFThpGr1uPn7Z3DsJwexbMVqDjn9hwAMPerjXHbBCey+a0+OOucmps2Z/8H+3zznGL504hCqqqu5/KZxPDFxTqlCL6mFi1fwtavvYsny1VRUiDNPOoQLP394qcMquct//HuemDibbl068PBvLgXgnVVr+MY1d7Hgrbfpu2NXRl11Fp07ti9xpM1XTjXVFm1SkzRS0reLVPYBkmakcx+OUg7/F+7540ROHXHLR7bNeeVNzrr0Np6Z+spHtu++244M+/T+DPn8dZw64pfcdNlpVJTRX+sstWlTwdUjTuaZP1zBI7d/izvG/Z2XXl1U6rBKbthxB3LHjy/4yLZf3f0EQ/YfwITffY8h+w/gV3dPKFF02ZJU0JIH5dNPoXG3AheQDCUbwMZzJpbcM1NfYcWqtR/Z9q/XFvPy60s22veET+3D+MemsH5DJfPfXM68N5ZxwMBdWyjSfNmxe2f23SMZgt1hu234t117smjJyhJHVXqf2Lc/XTp9tBb6+DMzGXbsgQAMO/ZAHnt6Zn0fLTtOqoCksyS9KGm6pLvqef98Sc+n798nqX26fbikmen2p9JtAyU9J2laWuaAOmX1AjpFxLMREcBv+XBOxLLUa4fOLFy84oP1N5esoNcOnUsYUT7Mf3M5M/61kAMG7VLqUHJp2dur6dGtEwA9unVi+Yp3SxxRBrQZSw4U5Z6qpIHAFcChEbFMUtd6dhsfEbel+18LnAvcDFwJHBsRCyV1Sfe9CPh5RPyvpHZA3TFrfUhmlKlR0LyHeVbfX91odNKx1u3dte/z5e/+mmsvGUbH7bYtdTjWQkR+aqGFKFZN9UhgXEQsA4iIujNtAwyS9HdJM4AzSB5ZAPA0cKek8/kweT4LfE/SZcAuEbGuTlkFz3so6QJJL0h6ISrrFpMfby55hz49P3hUDr17bM9by7bcS94NlVV8+bu/5tRjB/PZI/YtdTi51b1rR5YsXwXAkuWr6LZ9hxJHlI2KioqCljwoVhSi8clc7wQujoi9gauBbQAi4iLgv0jmMZwmqVtE3A2cCKwDHpV0ZJ2yFpDMdVhjk/MeRsToiBgcEYPVNr+1nYefepFhn96fdlu1Zefe3ei/8w5MnvVaqcMqiYjgkuvu5t927clXv1j3v95qO+qQgYx/9HkAxj/6PEcfMqjEEWWjnO6pFqtL1QTgfkk/jYjlkrrWU1vtCCyStBVJTXUhgKT+ETEJmCTpc8BOkjoD8yJilKR+wD7AEzUFpY9AWC3pYGAScBbJrYRcuf3aczj0gAF069KBmX/8AdeP/jMrVq3hx98eTvftO/CHn17EjH8t5NQRt/DPeW/xf49PZeLYK6isquY7N4ylunrLvP6fNH0eYx9+nr369+bwM38MwBVf/SyfPmRgI59s3S75wV1MmvYyK1au4dDhV/ONc47lwi8cxYirf8u9f55E7x7bc/PIs0odZvPl6H5pIRRFulEn6WzgO0AVMDUizpE0Eng3Im6S9FXgUuB1YAbQMd1nPEnrvUiS8yUkTzf8ErABeAv4Yt0kLWkwSe13W+Bh4OvRyJeraN8jtt79tIy+ceuzdOKoUoeQeyvXVZY6hFw74YghTJ86uVkpsW33ftHlsz8saN/lY74wOcPHqTRJ0Tr/R8QYPnxCYc22kbVe30rSDaru54bVU9yP0qWh470AtI5rHTP7QLk1VHlElZnlnoepmpllReU1TNVJ1cxyz0nVzCxDTqpmZhlxQ5WZWdbKJ6c6qZpZzoncDEEthJOqmeWeL//NzLJUPjnVSdXM8s81VTOzjORpBqpCOKmaWe45qZqZZchj/83MMuSaqplZVspsQpXy6VFrZlskAVJhS6NlSd+UNCt9YvM9kraR1FXSY5Lmpj+3b7ykTXNSNbOcK+z5VI3VZiX1AUYAgyNiEMmDRU8nebLIhIgYQPK0kcubE62TqpnlXkWFCloK0BbYVlJboD3JA0KH8uFTSsYAJzUr1uZ82Mys6Aq89E8rqt1rHkGfLhfUFBMRC4GbgPnAImBlRPwF6BkRi9J9FgE9mhOuG6rMLNcEhdZCAZZt6sF/6b3SocBuwDvAvZK+lEmQtbimama5l1FD1dHAqxGxNCI2AOOBQ4DFknolx1EvYElzYnVSNbPcy6KhiuSy/2BJ7ZXsfBQwB3gQODvd52zggebE6st/M8u3ArtLNSYiJkkaB0wBKoGpwGigAzBW0rkkiXd4c47jpGpmuSaU2STVEXEVcFWdze+T1Foz4aRqZrlXRgOqnFTNLP/KaZiqk6qZ5VtG91RbipOqmeVaMva/fLKqk6qZ5V4Z5VQnVTPLv80YUVVyTqpmlm9lNp/qFp1Ud9u1F9f/5nulDiO3IkodQf5169Cu1CHkWtsMapg186mWiy06qZpZOfDTVM3MMlVGOdVJ1cxyTm6oMjPLjPupmpllzEnVzCxDZZRTnVTNLP9cUzUzy4onVDEzy04ySXX5ZFUnVTPLvYoyqqo6qZpZ7pVRTnVSNbN8kydUMTPLVhndUt10UpV0M7DJeYoiYkRRIjIzq6O1NFS90GJRmJltgkh6AJSLTSbViBhTe13SdhGxpvghmZl9VBlVVKlobAdJQyTNBuak6/tK+mXRIzMzA1Ayn2ohSx40mlSBnwHHAssBImI6cFgxgzIzq00qbMmDglr/I+KNOn8FqooTjpnZR4nW1/n/DUmHACGpHTCC9FaAmVlLKKfW/0Iu/y8Cvgb0ARYC+6XrZmZFV+ilf14qs43WVCNiGXBGC8RiZlavcrr8L6T1v5+khyQtlbRE0gOS+rVEcGZmUNNXtfGloLKkLpLGSfqnpDlpD6eukh6TNDf9uX1TYy3k8v9uYCzQC+gN3Avc09QDmpltroy7VP0ceCQi9gD2JWkjuhyYEBEDgAnpepMUklQVEXdFRGW6/I4Ghq+amWUpaf0vbGm0LKkTSZfQXwNExPqIeAcYCtQMeBoDnNTUeBsa+981ffmkpMuB35Mk088Df2rqAc3MNos2a5Lq7pJqD7EfHRGja633A5YCv5G0LzAZ+AbQMyIWAUTEIkk9mhpuQw1Vk0mSaM23ubDWewH8oKkHNTPbHJtxab8sIgY38H5bYH/g6xExSdLPacal/qYOUK+I2C3LA5mZNUXN5X9GFgALImJSuj6OJKkultQrraX2ApY09QAFjaiSNAjYC9imZltE/LapBzUz2xxZjeuPiLckvSFp94h4CTgKmJ0uZwPXpz8faOoxGk2qkq4CDidJqn8Gjgf+ATipmlmLyLiX6teB/01HiM4DvkzSaD9W0rnAfGB4UwsvpKZ6Kkm3g6kR8WVJPYHbm3pAM7PNIUGbDK//I2IaUN9916OyKL+QpLouIqolVabdEZaQtKBZE63fUMkPf3QXGyqrqK6q5sDBezDs5MP4xS/v5623lgOwdu37tG+/Nddec16Joy29997fwNCv/pz3N1RSVVXNZ4/Yj8vOP6HUYeXK48/M5rs/GUdVdTVnDj2Eb55zTKlDylRepvUrRCFJ9QVJXYDbSHoEvAs815SDSRoJvBsRNzXl842UfR1wFrB9RHTIuvwsbdW2DZdfegbbbNOOysoqrv3RXeyzT38u/o+TP9jn7t8/Tvttty5hlPmxdbu23PeLr9Oh/dZsqKzicxf+jKOG7MngQW5LBaiqquY7N4zl/l9cTO+eXTjy7Bs5/rC92aNfr1KHlpkyyqmNd/6PiP+IiHci4n+ATwNnR8SXix/aZnsI+ESpgyiEJLbZph2Q/EJUVVZ95J5RRPDcc3M4+KCBpQkwZyTRoX3yB2ZDZRUbKqvKquZSbJNnvUa/nbqza9/utNuqLcM+vT9//tuLpQ4rM0JUqLAlDxrq/L9/Q+9FxJSGCpZ0FvBtkj6tL0bEmXXePx+4AGgHvAycGRFrJQ0HriKZs3VlRBwmaSDwm3TfCuCUiJhbu7yImJiW21BYuVFdXc2VI+9g8ZIVHH3kAfTv3+eD91761xt06rwdO+7YtYEStixVVdUc/eUbeXXBUr5yyr9zwMBdSx1SbixaupI+PT8cqt675/ZMnvla6QLKWo5moCpEQ5f/P2ngvQCO3NSbaRK8Ajg0IpbVGp1V2/iIuC3d/1rgXOBm4Erg2IhYmN52gGT6wZ9HRE2LXZsGYmuQpAtIkjnde/VpZO/iqaio4NprzmPN2vcYdfM4FixYQt++ySCOiZNmMcS11I9o06aCJ397GStXr+Wcy29nzitvsmf/3qUOKxciNh41Xk5JqBDlUlmChjv/H9GMco8ExqXTBhIRb9ezz6A0mXYBOgCPptufBu6UNBYYn257FrhCUl+SZDx3o9IKlA5ZGw3Qf699Sz6HwXbtt2GP3XfhxRnz6Nu3B1VV1bww+SWuueorpQ4tlzp3bM8h+w/giYlznFRTvXt0YeHiFR+sv7l4BTt271zCiLIloE0ZJdVCJlRpCtH4pCt3AhdHxN7A1aQDCyLiIuC/gJ2AaZK6RcTdwInAOuBRSZusJZeDVavWsGbtewCsX7+BWbNfpVevbgAfvO7atVMpQ8yVZStWs3L1WgDWvbeep55/iQG79CxxVPmx/1678Mr8pby+cBnrN1Qy/rEpHH/YPqUOK1NZTajSEgoaUdUEE4D7Jf00IpZL6lpPbbUjsEjSViSTYC8EkNQ/HUI2SdLngJ0kdQbmRcSodC7XfYAnihR70b2zcg2jb3+IqK6mOoKDDtyTj+83AICJk2b70r+OxctX8fVrfkdVdRARnHjkfhzzyUGlDis32rZtww2XnsYpI26hqio448SD2bN/62n5h/wkzEIUJalGxKy0i9PfJFUBU4Fz6uz2fWAS8DowgyTJAtwoaQBJbXcCMJ1kbO6XJG0A3gKuqXtMSTcAXwTaS1oA3B4RIzP+apnYeaceXHv1ufW+d8F5n2vhaPJv4Mf68MRvLyt1GLl2zKEDOebQ1vnHOHlUSvlk1UKGqYqkJtkvIq6RtDOwY0Q02Fc1Isbw4fyENdtG1np9K3BrPZ8bVk9xP0qXho53KXBpQ/uYWXkqp5pqIfdUfwkMAb6Qrq8GbilaRGZmdbSqB/8BB0XE/pKmAkTEirRbk5lZ0Qlom5eMWYBCkuoGSW1IW/Ml7QBUFzUqM7NayiinFpRURwH3Az3SxqdTSbo8mZkVnXI0BLUQjSbVdBTTZJJpsQScFBFzih6ZmVmqjHJqQa3/OwNrSSYs+WBbRMwvZmBmZjXKqfW/kMv/P/HhAwC3AXYDXgJaZ6c4M8sVke0k1cVWyOX/3rXX09mrLtzE7mZm2crRENRCbPaIqoiYIunAYgRjZlYfZf2UqiIq5J7qt2qtVpA8M3tp0SIyM6sl40dUF10hNdWOtV5Xktxjva844ZiZbazVJNW003+HiPhOC8VjZraRVjGhiqS2EVHZ0GNVzMyKLXlEdamjKFxDNdXnSO6fTpP0IHAvsKbmzYgYv6kPmpllqVWNqAK6AstJHpFS0181+PBRJ2ZmRdOaGqp6pC3/M/kwmdYo+bOdzGzLUUYV1QaTahuSB/LV93WcVM2shYiKVtJPdVFEbPTYEjOzliRaT021jL6GmbVagrZldFO1oaR6VItFYWa2Ca2mplrPI6XNzEqinLpUlVGXWjPbUmX54D9JbSRNlfTHdL2rpMckzU1/bt+cWJ1UzSzXRJKoClkK9A2g9tNLLgcmRMQAYEK63mROqmaWb0ou/wtZGi1K6gt8Bri91uahwJj09RjgpOaEu9nzqZqZtaRkRFXB91S7S3qh1vroiBhda/1nwKV8dPa9nhGxCCAiFknq0Zx4nVTNLPc2o5lqWUQMrrcM6bPAkoiYLOnwbCLbmJOqmeVeRo3/hwInSjqB5Hl7nST9DlgsqVdaS+0FLGnOQXxP1cxyTkiFLQ2JiO9GRN+I2BU4HXgiIr4EPAicne52NvBAc6J1TdXMcq2m9b+IrgfGSjoXmA8Mb05hTqpmlntZd/6PiL8Cf01fLyfDEaRbdFKtJlhXWVXqMHJrq7a+O9SY1es2lDqEXKuKDCa0Uyt5nIqZWR60wOV/ppxUzSz3XFM1M8tQ+aRUJ1UzyzkBbVxTNTPLThnlVCdVM8s7oTK6AeCkama555qqmVlGki5V5ZNVnVTNLN82Y1b/PHBSNbPcK6dnVDmpmlmuJZNUlzqKwjmpmlnuufXfzCxDZXT176RqZvnnmqqZWUZ8T9XMLEsFPn46L5xUzSz3yielOqmaWc4ll//lk1adVM0s98onpTqpmlk5KKOs6qRqZrnny38zswyVT0p1UjWzclBGWdVJ1cxyTXhElZlZdjyfqplZtsoopzqpmlneCZVRVdVJ1cxyr4xyqpOqmeWbKK/L/4pSB2Bm1igVuDRWjLSTpCclzZE0S9I30u1dJT0maW76c/umhuqkama5pwL/FaAS+M+I2BM4GPiapL2Ay4EJETEAmJCuN4kv/0uourqaH147hi5dOnLxiFNZs2Ydt/3qAZYvX0W3bp04/8KT2G67bUodZi48/sxsvvuTcVRVV3Pm0EP45jnHlDqkXHll/hK+NnLMB+vz31zOt75yPOed9qkSRpWdrO6pRsQiYFH6erWkOUAfYChweLrbGOCvwGVNOUaLJlVJI4F3I+KmjMttD9wL9AeqgIciosl/aVrKhMdfYMde3Xhv3XoAHnl4InvsuSvHHX8wjzw8kUcensgppx5e2iBzoKqqmu/cMJb7f3ExvXt24cizb+T4w/Zmj369Sh1abvTfuQeP3PEdIDlfnzhlJMcdtneJo8rI5vVT7S7phVrroyNidL3FSrsCHwcmAT3ThEtELJLUo6nhtqbL/5siYg+Sk3SopONLHVBDVry9ihkz5vHJT+77wbbp015myJBBAAwZMojp0+aWKrxcmTzrNfrt1J1d+3an3VZtGfbp/fnz314sdVi59fTkf7Fz72703bFrqUPJzGZc/i+LiMG1lk0l1A7AfcAlEbEqy1iLllQlnSXpRUnTJd1Vz/vnS3o+ff++tLaJpOGSZqbbn0q3DZT0nKRpaZkDapcVEWsj4sn09XpgCtC3WN8tC2P/MIFTTj0c1Xr4zqpVa+jcpQMAnbt0YPXqNaUKL1cWLV1Jn54fthv07rk9i5auLGFE+fbgE1MZetT+pQ4jMyKpqRayFFSetBVJQv3fiBifbl4sqVf6fi9gSVPjLUpSlTQQuAI4MiL2Bb5Rz27jI+LA9P05wLnp9iuBY9PtJ6bbLgJ+HhH7AYOBBQ0cuwvwOZKbzbn04vSX6dhpO3bZZcdSh1IWImKjbeXUb7Elrd9QyWNPz+IzR+xX6lAylVHjP0pGEfwamBMR/13rrQeBs9PXZwMPNDXWYt1TPRIYFxHLACLi7Xr2GSTpWqAL0AF4NN3+NHCnpLFAzV+RZ4ErJPUlScb1XhdLagvcA4yKiHmb2OcC4AKAbjv2acp3a7ZXXlnI9GlzmTnjFTZsqGLde+/z69sfolOn7Vj5zrt07tKBle+8S8eO25Ukvrzp3aMLCxev+GD9zcUr2LF75xJGlF9/nTiHQQP6sEPXjqUOJVvZ/RE9FDgTmCFpWrrte8D1wFhJ5wLzgeFNPUCxkqqAjasXH3UncFJETJd0DmnLW0RcJOkg4DPANEn7RcTdkial2x6VdF5EPFFPmaOBuRHxs00dNL3HMhpgt732aSzGojh52Kc4eVjSKvvSS/N57NHnOPe8zzHu3id59tmZHHf8wTz77Ez23e9jpQgvd/bfaxdemb+U1xcuo1ePLox/bAq3/eCcUoeVSw9MmMrQo1vPpX+NrCapjoh/sOkUfVQWxyjWPdUJwGmSukHSsbaefToCi9L7G2fUbJTUPyImRcSVwDJgJ0n9gHkRMYqkmr5P3cLSWm9n4JLMv00LOe74g5k9+zW+f8VoZs9+jeOOP7jUIeVC27ZtuOHS0zhlxC0cNPxaTjr64+zZ3y3/da17bz1/f+Eljjtso1+PspfV5X9LKEpNNSJmSboO+JukKmAqcE6d3b5P0pXhdWAGSZIFuDFtiBJJcp5O0hH3S5I2AG8B19QuKL0tcAXwT2BKOvnCLyLi9uy/XbZ2331ndt99ZwA6dNiWb/3n6SWOKJ+OOXQgxxw6sNRh5Nq227TjxT9eV+owiiMvGbMAReunGhFjSDrR1t42stbrW4Fb6/ncsHqK+1G6bOpYCyir025mhfIk1WZmWfIk1WZm2SqjnOqkamZ550mqzcwyVUY51UnVzPItT92lCuGkamb5V0ZZ1UnVzHLPXarMzDLke6pmZlkRVDipmpllqXyyqpOqmeVazSTV5cJJ1cxyr4xyqpOqmeWfa6pmZhnyMFUzswyVT0p1UjWznNucJ6XmgZOqmeWeR1SZmWWpfHKqk6qZ5V8Z5VQnVTPLO2X2iOqW4KRqZrlWbiOqKkodgJlZa+KaqpnlXjnVVJ1UzSz33KXKzCwr7vxvZpadcmuoclI1s9zz5b+ZWYbKqabqLlVmlnsqcGm0HOk4SS9JelnS5cWI1UnVzPIvg6wqqQ1wC3A8sBfwBUl7ZR2qk6qZ5ZqACqmgpRGfAF6OiHkRsR74PTA083gjIusyy4akpcDrpY6jlu7AslIHkWM+P43L2znaJSJ2aE4Bkh4h+V6F2AZ4r9b66IgYnZZzKnBcRJyXrp8JHBQRFzcnvrq26Iaq5v5nZ03SCxExuNRx5JXPT+Na4zmKiOMyKqq+qmzmtUpf/pvZlmIBsFOt9b7Am1kfxEnVzLYUzwMDJO0mqR1wOvBg1gfZoi//c2h0qQPIOZ+fxvkcbUJEVEq6GHgUaAPcERGzsj7OFt1QZWaWNV/+m5llyEnVzCxDTqpFJmmkpG8XqewDJM1Ih9yNkspphHSiyOfnOklvSHq3GOW3lGKdI0ntJf1J0j8lzZJ0fdbH2BI5qZa3W4ELgAHpklV/vtbiIZJRNLZpN0XEHsDHgUMlHV/qgMqdk2qGJJ0l6UVJ0yXdVc/750t6Pn3/Pknt0+3DJc1Mtz+Vbhso6TlJ09IyB9QpqxfQKSKejaS18bfASS3wNZusJc8PQERMjIhFxf9m2WnJcxQRayPiyfT1emAKSd9Na46I8JLBAgwEXgK6p+td058jgW+nr7vV2v9a4Ovp6xlAn/R1l/TnzcAZ6et2wLZ1jjcYeLzW+r8Dfyz1ecjL+alz7HdL/f3L4Bx1AeYB/Up9Hsp9cU01O0cC4yJiGUBEvF3PPoMk/V3SDOAMkl8igKeBOyWdT9J/DuBZ4HuSLiMZP72uTlktMuQuQy19fspRSc6RpLbAPcCoiJiX3dfZMjmpZkc0ntTuBC6OiL2Bq0kmfyAiLgL+i2QI3TRJ3SLibuBEYB3wqKQj65S1gI9eqhVlyF2GWvr8lKNSnaPRwNyI+Fnzv4I5qWZnAnCapG4AkrrWs09HYJGkrUhqGaT79o+ISRFxJckMQztJ6gfMi4hRJEPp9qldUCT3CldLOjht9T8LeKAYXywjLXp+ylSLnyNJ1wKdgUsy/zZbKCfVjEQy3O064G+SpgP/Xc9u3wcmAY8B/6y1/ca0a9RM4ClgOvB5YKakacAeJA1RdX0VuB14GXgFeDijr5O5UpwfSTdIWgC0l7RA0sgsv1PWWvocSeoLXEEyYfOUtEHrvIy/1hbHw1TNzDLkmqqZWYacVM3MMuSkamaWISdVM7MMOamamWXISdU2SVJV2s1mpqR7a8aZN7GsO5U8zRJJt6uB561LOlzSIU04xmuSNnrq5qa219lns2ayUhFn17Ly5qRqDVkXEftFxCBgPXBR7Tcltan/Yw2LiPMiYnYDuxwObHZSNcsDJ1Ur1N+Bj6W1yCcl3Q3MkNRG0o3pzEkvSroQQIlfSJot6U9Aj5qCJP1V0uD09XGSpqSzK02QtCtJ8v5mWkv+d0k7pDMyPZ8uh6af7SbpL5KmSvoV9c+H8BGS/k/SZCXzh15Q572fpLFMkLRDuq2/pEfSz/xd0h5ZnExrvfzgP2tUOuHG8cAj6aZPAIMi4tU0MYaEnAQAAAIrSURBVK2MiAMlbQ08LekvJPNz7g7sDfQEZgN31Cl3B+A24LC0rK4R8bak/yGZWeqmdL+7gZ9GxD8k7Uzy4LY9gauAf0TENZI+QzK3bGO+kh5jW+B5SfdFxHJgO2BKRPynpCvTsi8mGRd/UUTMlXQQ8EuSiU/M6uWkag3ZNh3iCElN9dckl+XPRcSr6fZjgH1q7peSjCMfABwG3BMRVcCbkp6op/yDgadqytrErEwARwN76cMHG3SS1DE9xrD0s3+StKKA7zRC0snp653SWJcD1cAf0u2/A8ZL6pB+33trHXvrAo5hWzAnVWvIuojYr/aGNLmsqb2JZE7PR+vsdwKNz7hUyKxMkNymGlJ36ro0loLHWUs6nCRBD4mItZL+SjrLUz0iPe47dc+BWUN8T9Wa61Hgq+msSUj6N0nbkUzqcXp6z7UXcEQ9n30W+JSk3dLP1szKtJpkNqYafyG5FCfdrybJPUU6U5OSx4Bs30isnYEVaULdg6SmXKMCqKltf5HktsIq4FVJw9NjSNK+jRzDtnBOqtZct5PcL52SzpD0K5IroPuBuSQz0t8K/K3uByNiKcl90PHprEw1l98PASfXNFQBI4DBaUPYbD7shXA1cJikKSS3IeY3EusjQFtJLwI/ACbWem8NMFDSZJJ7ptek288Azk3jmwUMLeCc2BbMs1SZmWXINVUzsww5qZqZZchJ1cwsQ06qZmYZclI1M8uQk6qZWYacVM3MMvT/NDAuNMwMSVwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp = plot_confusion_matrix(classifier, X_class_no_test_prep, y_class_no_test_prep,\n",
    "                                 display_labels=classes,\n",
    "                                 cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-9ef91beffd20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_prob_class1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_prob_class1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_prob_class1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.25\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mpred_prob_class1\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpred_prob_class1\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true = y_class_no_test_prep\n",
    "classifier = SVC(probability=True)\n",
    "classifier.fit(X_class_no_train_prep, y_class_no_train_prep)\n",
    "\n",
    "pred_prob_class1 = classifier.predict_proba(X_class_no_test_prep)\n",
    "\n",
    "classes=['class 0','class 1','class 2']\n",
    "\n",
    "y_pred = np.zeros(len(pred_prob_class1),dtype=int)\n",
    "y_pred[pred_prob_class1 < 0.25] = 0\n",
    "y_pred[pred_prob_class1 >= 0.25 & pred_prob_class1 <= 0.75] = 1\n",
    "y_pred[pred_prob_class1 >= 0.75] = 2\n",
    "#\n",
    "#confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, fbeta_score\n",
    "\n",
    "#make predicted and true features\n",
    "y_true = df['y_true']\n",
    "pred_prob_class1 = df['pred_prob_class1']\n",
    "\n",
    "#make empty lists to store the different scores\n",
    "accuracy = []\n",
    "recall = []\n",
    "precision = []\n",
    "f1 = []\n",
    "f05 = []\n",
    "f15 = []\n",
    "\n",
    "# the sorted predicted probabilities serve as critical probabilities\n",
    "p_crits = np.sort(pred_prob_class1) \n",
    "\n",
    "for i in range(len(p_crits)):\n",
    "    p_crit = p_crits[i]\n",
    "    # If predicted probability is < p_crit (by default 0.5), predicted class is 0, otherwise it is 1.\n",
    "    y_pred = np.zeros(len(pred_prob_class1),dtype=int)\n",
    "    y_pred[pred_prob_class1 < p_crit] = 0\n",
    "    y_pred[pred_prob_class1 >= p_crit] = 1\n",
    "    #accuracy\n",
    "    accuracy.append(accuracy_score(y_true,y_pred))\n",
    "    #recall\n",
    "    recall.append(recall_score(y_true,y_pred))\n",
    "    #precision\n",
    "    precision.append(precision_score(y_true,y_pred))\n",
    "    #f1\n",
    "    f1.append(fbeta_score(y_true,y_pred,1))\n",
    "    #f0.5\n",
    "    f05.append(fbeta_score(y_true,y_pred,0.5))\n",
    "    #f1.5\n",
    "    f15.append(fbeta_score(y_true,y_pred,1.5))\n",
    "\n",
    "#plot the accuracy, precision, recall, f0.5, f1, f1.5 scores using the sorted predicted probabilities as critical probabilities\n",
    "plt.plot(p_crits,accuracy, label = \"accuracy\")\n",
    "plt.plot(p_crits,recall, label = \"recall\")\n",
    "plt.plot(p_crits, precision, label = \"precision\")\n",
    "plt.plot(p_crits,f1, label = \"f1\")\n",
    "plt.plot(p_crits,f05, label = \"f05\")\n",
    "plt.plot(p_crits,f15, label = \"f15\")\n",
    "plt.xlabel('evaluation metrics')\n",
    "plt.ylabel('critical probabilities')\n",
    "plt.title('eval metrics vs critical probabilities')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max critical probabilities for each scores\n",
    "print(\"best critical probability for maximizing accuracy\", p_crits[np.argmax(accuracy)])\n",
    "print(\"best critical probability for maximizing recall\",p_crits[np.argmax(recall)]) \n",
    "print(\"best critical probability for maximizing precision\",p_crits[np.argmax(precision)]) \n",
    "print(\"best critical probability for maximizing f1\",p_crits[np.argmax(f1)])\n",
    "print(\"best critical probability for maximizing f0.5\",p_crits[np.argmax(f05)])\n",
    "print(\"best critical probability for maximizing f1.5\",p_crits[np.argmax(f15)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "- We see that the monotone increasing graph is precision, which becomes optimized at the critical probability ~ 0.94, which is very close to 1 as we see on the graph. The monotone decreasing graph is recall, which is optimized at the critical probability ~ 0. \n",
    "- The critical probability that maximizes accuracy is ~0.28, f1 is also ~0.28, f0.5 is ~0.72, and f1.5 is ~0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df['y_true']\n",
    "pred_prob_class1 = df['pred_prob_class1']\n",
    "\n",
    "#make fpr and tpr lists\n",
    "fpr = np.zeros(len(y_true))\n",
    "tpr = np.zeros(len(y_true))\n",
    "#make distance list\n",
    "distance = np.zeros(len(y_true))\n",
    "\n",
    "# the sorted predicted probabilities serve as critical probabilities\n",
    "p_crits = np.sort(pred_prob_class1) \n",
    "\n",
    "#loop through the critical probailities to calculate tpr and fpr rates\n",
    "for i in range(len(p_crits)):\n",
    "    p_crit = p_crits[i]\n",
    "    \n",
    "    y_pred = np.zeros(len(y_true))\n",
    "    y_pred[pred_prob_class1 < p_crit] = 0\n",
    "    y_pred[pred_prob_class1 >= p_crit] = 1\n",
    "    \n",
    "    C = confusion_matrix(y_true,y_pred) \n",
    "    \n",
    "    tpr[i] = C[1,1]/(C[1,0]+C[1,1])\n",
    "    fpr[i] = C[0,1]/(C[0,0]+C[0,1])\n",
    "    \n",
    "    #calculate minimum distance\n",
    "    distance[i] = np.sqrt(np.power(fpr[i]-0, 2) + np.power(tpr[i]-1,2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the ROC curve\n",
    "plt.plot(fpr,tpr)\n",
    "plt.xlabel('fpr')\n",
    "plt.ylabel('tpr')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_p_crit = p_crits[np.argmin(distance)]\n",
    "print(\"best critical probability\", best_p_crit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
